{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af87aee7",
   "metadata": {},
   "source": [
    "# GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b9c28b",
   "metadata": {},
   "source": [
    "가장 주인공 같은 인물, 혹은 가장 움직이는게 좋을 거 같은 인물 하나를 지정해서 설명해달라고 해야할 것 같다.\n",
    "\n",
    "seg_prompt는 위치로 인물을 지정하는 게 가장 정확한 듯하다. 그리고 손에 들고 있는 것까지 언급을 해주면 다 같이 마스킹 할 수 있게끔 하였다. 근데 다른 공통적인 물건까지 포함시키면 전혀 다른 위치의 해당 물건이 같은 마스크가 되어버린다.\n",
    "\n",
    "motion_prompt는 다른 물건 언급 없이 동작 자체만 설명하는 것이 좋을 것 같다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a8fbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt 프롬프트 입니다.\n",
    "# 워크스페이스에서 API 호출이 안되어 외부에서 돌린 결과를 임의로 가져와서 사용하였습니다.\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert in analyzing storybook illustrations and describing animations for human-like characters. Return results in a dictionary format.\"},\n",
    "        {\n",
    "            \"role\": \"user\", \"content\": \"\"\"\n",
    "Analyze the provided storybook page image.\n",
    "1. Regocnize the texts and illustrations on the storybook image.\n",
    "2. Choose one human character that you think would be best to animate.\n",
    "3. Describe the character's position on the image and what he/she is holding.\n",
    "4. Suggest a simple motion in HumanML3D style based on context. You should focus only on the character's motion and do not include any other objects.\n",
    "\n",
    "Output Format:\n",
    "{   [\n",
    "        \"name\": \"One-word name for the character\",\n",
    "        \"description\": \"Name and location and object. ex) A boy on left side holding a gun.\",\n",
    "        \"motion\": \"Simple motion description for the character in HumanML3D dataset style. Start with 'A person is'.\"\n",
    "    ]\n",
    "}\n",
    "\"\"\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": [{\"type\": \"image_url\", \"image_url\": {\"url\":  f\"data:image/jpeg;base64,{base64_image}\"}}]}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb872838",
   "metadata": {},
   "source": [
    "# 데이터 경로 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dab59d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "image_name = \"a1\"  # 이미지 이름 지정\n",
    "data_dir= \"/home/jovyan/data/axe/\" + image_name + \"/\"  # 책 이름 지정\n",
    "image_path = data_dir + image_name + \".png\"\n",
    "char_dir = data_dir + \"char/\"\n",
    "os.makedirs(char_dir, exist_ok=True)\n",
    "inpaint_dir = data_dir + \"inpaint/\"\n",
    "os.makedirs(inpaint_dir, exist_ok=True)\n",
    "\n",
    "motion_path = char_dir + image_name + \".bvh\"\n",
    "\n",
    "seg_prompt = \"A boy on the left side.\"  # segment를 위한 prompt\n",
    "motion_prompt = \"\\\"A person is running energetically with a skipping motion.\\\"\"  # motion 생성을 위한 prompt\n",
    "\n",
    "env_vars = {  # 커널을 변경하여도 변수 동일하게 사용하기 위해 별도의 파일에 저장\n",
    "    \"data_dir\": data_dir,\n",
    "    \"image_name\": image_name,\n",
    "    \"image_path\": image_path,\n",
    "    \"char_dir\": char_dir,\n",
    "    \"motion_path\": motion_path,\n",
    "    \"inpaint_dir\": inpaint_dir,\n",
    "    \"seg_prompt\": seg_prompt,\n",
    "    \"motion_prompt\": motion_prompt\n",
    "}\n",
    "\n",
    "with open(\"env_vars.json\", \"w\") as f:\n",
    "    json.dump(env_vars, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c23ee45",
   "metadata": {},
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63169f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 파일에서 변수 읽기\n",
    "with open(\"env_vars.json\", \"r\") as f:\n",
    "    env_vars = json.load(f)\n",
    "\n",
    "# 불러온 변수 사용\n",
    "data_dir = env_vars.get(\"data_dir\")\n",
    "image_name = env_vars.get(\"image_name\")\n",
    "image_path = env_vars.get(\"image_path\")\n",
    "char_dir = env_vars.get(\"char_dir\")\n",
    "motion_path = env_vars.get(\"motion_path\")\n",
    "inpaint_dir = env_vars.get(\"inpaint_dir\")\n",
    "seg_prompt = env_vars.get(\"seg_prompt\")\n",
    "motion_prompt = env_vars.get(\"motion_prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccfb9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from lang_sam import LangSAM\n",
    "import numpy as np\n",
    "import cv2\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32e9cf86-c6f1-43e3-a9bf-ae026d129294",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LangSAM(sam_type=\"sam2.1_hiera_large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9210a5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pil = Image.open(image_path).convert(\"RGB\")\n",
    "result = model.predict([image_pil], [seg_prompt])[0]\n",
    "\n",
    "mask = np.logical_or.reduce(result[\"masks\"]).astype(int)  # 생성된 모든 mask 하나로 통합\n",
    "mask = np.asarray(mask * 255, dtype=np.uint8)\n",
    "\n",
    "kernel = np.ones((10, 10), np.uint8)\n",
    "dilated_mask = cv2.dilate(mask, kernel, iterations=1)  # inpainting을 위한 dilated mask 생성\n",
    "\n",
    "bbox = np.array([np.min(result[\"boxes\"][:, 0]), np.min(result[\"boxes\"][:, 1]), np.max(result[\"boxes\"][:, 2]), np.max(result[\"boxes\"][:, 3])], dtype=np.float32)\n",
    "l, t, r, b = [round(x) for x in bbox]\n",
    "cropped_image = image_pil.crop(bbox)\n",
    "cropped_mask = mask[t:b, l:r]\n",
    "\n",
    "with open(char_dir + \"/bounding_box.yaml\", 'w') as f:  # 전체 이미지에서 bounding box 위치 별도 저장\n",
    "        yaml.dump({\n",
    "            'left': l,\n",
    "            'top': t,\n",
    "            'right': r,\n",
    "            'bottom': b\n",
    "        }, f)\n",
    "\n",
    "cropped_image.save(char_dir + \"/texture.png\")  # character 생성을 위해 mask 위치만 crop한 이미지 저장\n",
    "mask = Image.fromarray(mask)\n",
    "dilated_mask = Image.fromarray(dilated_mask)\n",
    "cropped_mask = Image.fromarray(cropped_mask)\n",
    "\n",
    "mask.save(data_dir + image_name + \"_mask.png\")\n",
    "dilated_mask.save(inpaint_dir + image_name + \"_mask.png\")\n",
    "cropped_mask.save(char_dir + \"mask.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fc6d95",
   "metadata": {},
   "source": [
    "# Inpainting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "921e8034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 파일에서 변수 읽기\n",
    "with open(\"env_vars.json\", \"r\") as f:\n",
    "    env_vars = json.load(f)\n",
    "\n",
    "# 불러온 변수 사용\n",
    "data_dir = env_vars.get(\"data_dir\")\n",
    "image_name = env_vars.get(\"image_name\")\n",
    "image_path = env_vars.get(\"image_path\")\n",
    "char_dir = env_vars.get(\"char_dir\")\n",
    "motion_path = env_vars.get(\"motion_path\")\n",
    "inpaint_dir = env_vars.get(\"inpaint_dir\")\n",
    "seg_prompt = env_vars.get(\"seg_prompt\")\n",
    "motion_prompt = env_vars.get(\"motion_prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7adf9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.copy(image_path, inpaint_dir + image_name + \".png\")\n",
    "\n",
    "# 캐릭터가 제거된 배경 inpainting\n",
    "!cd lama && export TORCH_HOME=$(pwd) && export PYTHONPATH=$(pwd) && python bin/predict.py model.path=$(pwd)/big-lama indir={inpaint_dir} outdir={inpaint_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecc4815",
   "metadata": {},
   "source": [
    "# Pose Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57047807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 파일에서 변수 읽기\n",
    "with open(\"env_vars.json\", \"r\") as f:\n",
    "    env_vars = json.load(f)\n",
    "\n",
    "# 불러온 변수 사용\n",
    "data_dir = env_vars.get(\"data_dir\")\n",
    "image_name = env_vars.get(\"image_name\")\n",
    "image_path = env_vars.get(\"image_path\")\n",
    "char_dir = env_vars.get(\"char_dir\")\n",
    "motion_path = env_vars.get(\"motion_path\")\n",
    "inpaint_dir = env_vars.get(\"inpaint_dir\")\n",
    "seg_prompt = env_vars.get(\"seg_prompt\")\n",
    "motion_prompt = env_vars.get(\"motion_prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ffd760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import mmpose\n",
    "from IPython.display import Image, display\n",
    "import cv2\n",
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "from mmpose.apis import (inference_top_down_pose_model, init_pose_model, vis_pose_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34539e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_config = '/home/jovyan/mmpose/config.py'\n",
    "pose_checkpoint = '/home/jovyan/mmpose/best_AP_epoch_72.pth'  # meta에서 제공하는 스케치 이미지에 fine-tune된 custom 모델 사용\n",
    "cropped = cv2.imread(char_dir + \"/texture.png\")\n",
    "\n",
    "pose_model = init_pose_model(pose_config, pose_checkpoint)\n",
    "\n",
    "pose_results, _ = inference_top_down_pose_model(  # 관절 위치 추정\n",
    "    pose_model, char_dir + \"/texture.png\", person_results=None)\n",
    "\n",
    "# vis_result = vis_pose_result(\n",
    "#     pose_model,\n",
    "#     char_dir + \"/image.png\",\n",
    "#     pose_results)\n",
    "\n",
    "# cv2.imwrite(\"test.png\", vis_result)\n",
    "# display(Image(\"test.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54db07c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "kpts = np.array(pose_results[0]['keypoints'])[:, :2]\n",
    "\n",
    "skeleton = []\n",
    "skeleton.append({'loc' : [round(x) for x in (kpts[11]+kpts[12])/2], 'name': 'root'          , 'parent': None})\n",
    "skeleton.append({'loc' : [round(x) for x in (kpts[11]+kpts[12])/2], 'name': 'hip'           , 'parent': 'root'})\n",
    "skeleton.append({'loc' : [round(x) for x in (kpts[5]+kpts[6])/2  ], 'name': 'torso'         , 'parent': 'hip'})\n",
    "skeleton.append({'loc' : [round(x) for x in  kpts[0]             ], 'name': 'neck'          , 'parent': 'torso'})\n",
    "skeleton.append({'loc' : [round(x) for x in  kpts[6]             ], 'name': 'right_shoulder', 'parent': 'torso'})\n",
    "skeleton.append({'loc' : [round(x) for x in  kpts[8]             ], 'name': 'right_elbow'   , 'parent': 'right_shoulder'})\n",
    "skeleton.append({'loc' : [round(x) for x in  kpts[10]            ], 'name': 'right_hand'    , 'parent': 'right_elbow'})\n",
    "skeleton.append({'loc' : [round(x) for x in  kpts[5]             ], 'name': 'left_shoulder' , 'parent': 'torso'})\n",
    "skeleton.append({'loc' : [round(x) for x in  kpts[7]             ], 'name': 'left_elbow'    , 'parent': 'left_shoulder'})\n",
    "skeleton.append({'loc' : [round(x) for x in  kpts[9]             ], 'name': 'left_hand'     , 'parent': 'left_elbow'})\n",
    "skeleton.append({'loc' : [round(x) for x in  kpts[12]            ], 'name': 'right_hip'     , 'parent': 'root'})\n",
    "skeleton.append({'loc' : [round(x) for x in  kpts[14]            ], 'name': 'right_knee'    , 'parent': 'right_hip'})\n",
    "skeleton.append({'loc' : [round(x) for x in  kpts[16]            ], 'name': 'right_foot'    , 'parent': 'right_knee'})\n",
    "skeleton.append({'loc' : [round(x) for x in  kpts[11]            ], 'name': 'left_hip'      , 'parent': 'root'})\n",
    "skeleton.append({'loc' : [round(x) for x in  kpts[13]            ], 'name': 'left_knee'     , 'parent': 'left_hip'})\n",
    "skeleton.append({'loc' : [round(x) for x in  kpts[15]            ], 'name': 'left_foot'     , 'parent': 'left_knee'})\n",
    "\n",
    "\n",
    "char_cfg = {'skeleton': skeleton, 'height': cropped.shape[0], 'width': cropped.shape[1]}  # 각 관절의 위치 별도 저장\n",
    "\n",
    "with open(char_dir + '/char_cfg.yaml', 'w') as f:\n",
    "        yaml.dump(char_cfg, f)\n",
    "\n",
    "joint_overlay = cropped.copy()\n",
    "for joint in skeleton:\n",
    "        x, y = joint['loc']\n",
    "        name = joint['name']\n",
    "        cv2.circle(joint_overlay, (int(x), int(y)), 5, (0, 0, 0), 5)\n",
    "        cv2.putText(joint_overlay, name, (int(x), int(y+15)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, 2)\n",
    "cv2.imwrite(char_dir + '/joint_overlay.png', joint_overlay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c655df",
   "metadata": {},
   "source": [
    "# Motion Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "314ffc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 파일에서 변수 읽기\n",
    "with open(\"env_vars.json\", \"r\") as f:\n",
    "    env_vars = json.load(f)\n",
    "\n",
    "# 불러온 변수 사용\n",
    "data_dir = env_vars.get(\"data_dir\")\n",
    "image_name = env_vars.get(\"image_name\")\n",
    "image_path = env_vars.get(\"image_path\")\n",
    "char_dir = env_vars.get(\"char_dir\")\n",
    "motion_path = env_vars.get(\"motion_path\")\n",
    "inpaint_dir = env_vars.get(\"inpaint_dir\")\n",
    "seg_prompt = env_vars.get(\"seg_prompt\")\n",
    "motion_prompt = env_vars.get(\"motion_prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b53e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt로 motion 생성\n",
    "!cd momask-codes && python gen_t2m.py --gpu_id 0 --ext exp1 --motion_length 100 --text_prompt \"\"{motion_prompt}\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c83a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import glob\n",
    "import os\n",
    "\n",
    "source_dir = '/home/jovyan/momask-codes/generation/exp1/animations/0'\n",
    "files = glob.glob(f'{source_dir}/*.bvh')\n",
    "latest_file = max(files, key=os.path.getctime)\n",
    "shutil.copy(latest_file, motion_path)\n",
    "\n",
    "files = glob.glob(f'{source_dir}/*.mp4')\n",
    "latest_file = max(files, key=os.path.getctime)\n",
    "shutil.copy(latest_file, char_dir+image_name+\".mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09dd17b",
   "metadata": {},
   "source": [
    "# Animating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcf3695d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 파일에서 변수 읽기\n",
    "with open(\"env_vars.json\", \"r\") as f:\n",
    "    env_vars = json.load(f)\n",
    "\n",
    "# 불러온 변수 사용\n",
    "data_dir = env_vars.get(\"data_dir\")\n",
    "image_name = env_vars.get(\"image_name\")\n",
    "image_path = env_vars.get(\"image_path\")\n",
    "char_dir = env_vars.get(\"char_dir\")\n",
    "motion_path = env_vars.get(\"motion_path\")\n",
    "inpaint_dir = env_vars.get(\"inpaint_dir\")\n",
    "seg_prompt = env_vars.get(\"seg_prompt\")\n",
    "motion_prompt = env_vars.get(\"motion_prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "597c01f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from PIL import Image\n",
    "\n",
    "image = char_dir + \"texture.png\"\n",
    "with Image.open(image) as img:\n",
    "    width, height = img.size\n",
    "\n",
    "window_width = int(width * 1.5)\n",
    "window_height = int(height * 1.5)\n",
    "\n",
    "yaml_path = \"/home/jovyan/data/animating/config/mvc/pbl.yaml\"\n",
    "\n",
    "new_character_cfg = char_dir + \"char_cfg.yaml\"\n",
    "video_path = data_dir+ image_name + \".gif\"\n",
    "\n",
    "with open(yaml_path, 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# rendering 하는데 사용되는 config 파일 수정\n",
    "config['scene']['ANIMATED_CHARACTERS'][0]['character_cfg'] = new_character_cfg\n",
    "config['controller']['OUTPUT_VIDEO_PATH'] = video_path\n",
    "config['view']['WINDOW_DIMENSIONS'] = [window_width, window_height]  # 영상 크기 조정\n",
    "\n",
    "with open(yaml_path, 'w') as file:\n",
    "    yaml.dump(config, file, default_flow_style=False)\n",
    "\n",
    "\n",
    "yaml_path = \"/home/jovyan/data/animating/config/motion/test.yaml\"\n",
    "\n",
    "new_bvh = motion_path\n",
    "\n",
    "with open(yaml_path, 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# rendering 하는데 사용되는 config 파일 수정\n",
    "config['filepath'] = motion_path\n",
    "\n",
    "with open(yaml_path, 'w') as file:\n",
    "    yaml.dump(config, file, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb30729",
   "metadata": {},
   "outputs": [],
   "source": [
    "from animated_drawings import render\n",
    "render.start('/home/jovyan/data/animating/config/mvc/pbl.yaml')  # segment한 이미지에 관절 위치 정보 이용해서 생성한 모션 입히기, gif 파일로 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b128453",
   "metadata": {},
   "source": [
    "# 배경 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fa881c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip, ImageClip, CompositeVideoClip\n",
    "import yaml\n",
    "\n",
    "yaml_file = char_dir + \"bounding_box.yaml\"\n",
    "with open(yaml_file, 'r') as file:\n",
    "    bounding_box = yaml.safe_load(file)\n",
    "\n",
    "left = bounding_box['left']\n",
    "right = bounding_box['right']\n",
    "top = bounding_box['top']\n",
    "bottom = bounding_box['bottom']\n",
    "\n",
    "center_x = (left + right) / 2\n",
    "center_y = (top + bottom) / 2\n",
    "\n",
    "video_path = data_dir+ image_name + \".gif\"\n",
    "gif_file = video_path\n",
    "\n",
    "clip = VideoFileClip(gif_file, has_mask=True)\n",
    "\n",
    "adjusted_x = center_x - (clip.w / 2)\n",
    "adjusted_y = center_y - (clip.h / 2)\n",
    "\n",
    "background_file = inpaint_dir + image_name + \"_mask.png\"\n",
    "background = ImageClip(background_file)\n",
    "\n",
    "background = background.set_duration(clip.duration).set_fps(clip.fps)\n",
    "\n",
    "# inpaint된 배경과 gif 파일 결합\n",
    "final_clip = CompositeVideoClip([\n",
    "    background,\n",
    "    clip.set_position((adjusted_x, adjusted_y))\n",
    "])\n",
    "\n",
    "# 동영상으로 저장\n",
    "final_clip.write_videofile(image_name + \".mp4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
